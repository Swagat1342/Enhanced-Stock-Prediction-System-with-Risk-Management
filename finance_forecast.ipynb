{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/n+vj4zuZqmt0iOGfEUVZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Swagat1342/Enhanced-Stock-Prediction-System-with-Risk-Management/blob/main/finance_forecast.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKrJsg_6BDOZ",
        "outputId": "10b56aba-4d4a-4df2-b021-50828fff6494"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.12/dist-packages (0.2.66)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.12/dist-packages (2.19.0)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.12/dist-packages (5.24.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.32.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.0.12)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.4.0)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.12/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.12/dist-packages (from yfinance) (3.18.2)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.12/dist-packages (from yfinance) (4.13.5)\n",
            "Requirement already satisfied: curl_cffi>=0.7 in /usr/local/lib/python3.12/dist-packages (from yfinance) (0.13.0)\n",
            "Requirement already satisfied: protobuf>=3.19.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (5.29.5)\n",
            "Requirement already satisfied: websockets>=13.0 in /usr/local/lib/python3.12/dist-packages (from yfinance) (15.0.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.9.23)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorflow) (25.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tensorflow) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (4.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.17.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (1.75.1)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /usr/local/lib/python3.12/dist-packages (from tensorflow) (0.5.3)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from plotly) (8.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.8)\n",
            "Requirement already satisfied: cffi>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2024.2.2 in /usr/local/lib/python3.12/dist-packages (from curl_cffi>=0.7->yfinance) (2025.8.3)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.12/dist-packages (from keras>=3.5.0->tensorflow) (0.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.31->yfinance) (2.5.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.9)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.23)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install numpy pandas yfinance scikit-learn tensorflow plotly"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install alpha_vantage finnhub-python polygon-api-client\n"
      ],
      "metadata": {
        "id": "G_ZxCJLERZ0G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "from requests.adapters import HTTPAdapter\n",
        "from urllib3.util.retry import Retry\n",
        "from datetime import datetime, timedelta\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
        "from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n"
      ],
      "metadata": {
        "id": "_YifFxRARZmT"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# ğŸ”‘ API Keys Configuration\n",
        "# ======================================\n",
        "API_KEYS = {\n",
        "    'ALPHA_VANTAGE': \"YOUR_ALPHA_VANTAGE_API_KEY\",\n",
        "    'IEX_CLOUD': \"YOUR_IEX_CLOUD_API_KEY\",\n",
        "    'FINNHUB': \"YOUR_FINNHUB_API_KEY\",\n",
        "    'POLYGON': \"YOUR_POLYGON_API_KEY\"\n",
        "}\n"
      ],
      "metadata": {
        "id": "J5kcjH5FRZS9"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ======================================\n",
        "# ğŸ“Š Stock Data Fetcher Class\n",
        "# ======================================\n",
        "class StockDataFetcher:\n",
        "    def __init__(self, api_keys=None):\n",
        "        self.api_keys = api_keys or API_KEYS\n",
        "        self.session = self._make_session()\n",
        "        self.last_source = None\n",
        "\n",
        "    def _make_session(self):\n",
        "        session = requests.Session()\n",
        "        retries = Retry(total=3, backoff_factor=1,\n",
        "                       status_forcelist=[429, 500, 502, 503, 504])\n",
        "        session.mount('https://', HTTPAdapter(max_retries=retries))\n",
        "        return session\n",
        "\n",
        "    def fetch_alpha_vantage(self, symbol, interval='5min', outputsize='compact'):\n",
        "        \"\"\"Fetch from Alpha Vantage API\"\"\"\n",
        "        print(f\"\\nğŸ”¹ Trying Alpha Vantage for {symbol}...\")\n",
        "        try:\n",
        "            url = (\n",
        "                f\"https://www.alphavantage.co/query?\"\n",
        "                f\"function=TIME_SERIES_INTRADAY&symbol={symbol}\"\n",
        "                f\"&interval={interval}&apikey={self.api_keys['ALPHA_VANTAGE']}\"\n",
        "                f\"&outputsize={outputsize}\"\n",
        "            )\n",
        "            r = self.session.get(url, timeout=10)\n",
        "            data = r.json()\n",
        "\n",
        "            ts_key = f\"Time Series ({interval})\"\n",
        "            if ts_key not in data:\n",
        "                print(f\"âŒ Alpha Vantage Error: {data.get('Note', data.get('Error Message', 'Unknown'))}\")\n",
        "                return None\n",
        "\n",
        "            df = pd.DataFrame.from_dict(data[ts_key], orient=\"index\").astype(float)\n",
        "            df.index = pd.to_datetime(df.index)\n",
        "            df.rename(columns={\n",
        "                \"1. open\": \"open\", \"2. high\": \"high\",\n",
        "                \"3. low\": \"low\", \"4. close\": \"close\",\n",
        "                \"5. volume\": \"volume\"\n",
        "            }, inplace=True)\n",
        "            print(f\"âœ… Alpha Vantage Success â€” {len(df)} records\")\n",
        "            self.last_source = \"Alpha Vantage\"\n",
        "            return df.sort_index()\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Alpha Vantage failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def fetch_polygon(self, symbol, start_date=None, end_date=None, timespan='minute', multiplier=5):\n",
        "        \"\"\"Fetch from Polygon.io API\"\"\"\n",
        "        print(f\"\\nğŸ”¹ Trying Polygon.io for {symbol}...\")\n",
        "        try:\n",
        "            if not start_date:\n",
        "                start_date = (datetime.now() - timedelta(days=5)).strftime('%Y-%m-%d')\n",
        "            if not end_date:\n",
        "                end_date = datetime.now().strftime('%Y-%m-%d')\n",
        "\n",
        "            url = (\n",
        "                f\"https://api.polygon.io/v2/aggs/ticker/{symbol}/range/\"\n",
        "                f\"{multiplier}/{timespan}/{start_date}/{end_date}?\"\n",
        "                f\"apiKey={self.api_keys['POLYGON']}\"\n",
        "            )\n",
        "            r = self.session.get(url, timeout=10)\n",
        "            data = r.json()\n",
        "\n",
        "            if \"results\" not in data:\n",
        "                print(f\"âŒ Polygon.io Error: {data.get('error', 'No results')}\")\n",
        "                return None\n",
        "\n",
        "            df = pd.DataFrame(data[\"results\"])\n",
        "            df[\"t\"] = pd.to_datetime(df[\"t\"], unit=\"ms\")\n",
        "            df.rename(columns={\n",
        "                \"t\": \"timestamp\", \"o\": \"open\", \"h\": \"high\",\n",
        "                \"l\": \"low\", \"c\": \"close\", \"v\": \"volume\"\n",
        "            }, inplace=True)\n",
        "            df.set_index(\"timestamp\", inplace=True)\n",
        "            print(f\"âœ… Polygon.io Success â€” {len(df)} records\")\n",
        "            self.last_source = \"Polygon.io\"\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Polygon.io failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def fetch_finnhub(self, symbol):\n",
        "        \"\"\"Fetch current quote from Finnhub API\"\"\"\n",
        "        print(f\"\\nğŸ”¹ Trying Finnhub for {symbol}...\")\n",
        "        try:\n",
        "            url = f\"https://finnhub.io/api/v1/quote?symbol={symbol}&token={self.api_keys['FINNHUB']}\"\n",
        "            r = self.session.get(url, timeout=10)\n",
        "            data = r.json()\n",
        "\n",
        "            if \"c\" not in data or data.get(\"c\") == 0:\n",
        "                print(f\"âŒ Finnhub Error: No data available\")\n",
        "                return None\n",
        "\n",
        "            df = pd.DataFrame([{\n",
        "                \"open\": data.get(\"o\"),\n",
        "                \"high\": data.get(\"h\"),\n",
        "                \"low\": data.get(\"l\"),\n",
        "                \"close\": data.get(\"c\"),\n",
        "                \"volume\": None\n",
        "            }], index=[datetime.now()])\n",
        "            print(f\"âœ… Finnhub Success â€” Current ${data.get('c')}\")\n",
        "            self.last_source = \"Finnhub\"\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Finnhub failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def fetch_yfinance(self, symbol, period=\"5d\", interval=\"5m\"):\n",
        "        \"\"\"Fetch from Yahoo Finance (Fallback)\"\"\"\n",
        "        print(f\"\\nğŸ”¹ Trying Yahoo Finance for {symbol}...\")\n",
        "        try:\n",
        "            df = yf.download(symbol, period=period, interval=interval, progress=False)\n",
        "            if df.empty:\n",
        "                print(\"âŒ Yahoo Finance returned no data\")\n",
        "                return None\n",
        "\n",
        "            # Handle multi-level columns (for multi-ticker downloads)\n",
        "            if isinstance(df.columns, pd.MultiIndex):\n",
        "                df.columns = df.columns.droplevel(1)\n",
        "\n",
        "            # Standardize column names - handle both string and tuple columns\n",
        "            df.columns = [col.lower() if isinstance(col, str) else col[0].lower()\n",
        "                         for col in df.columns]\n",
        "\n",
        "            print(f\"âœ… Yahoo Finance Success â€” {len(df)} records\")\n",
        "            self.last_source = \"Yahoo Finance\"\n",
        "            return df\n",
        "        except Exception as e:\n",
        "            print(f\"âŒ Yahoo Finance failed: {e}\")\n",
        "            return None\n",
        "\n",
        "    def get_stock_data(self, symbol, prefer_source=None):\n",
        "        \"\"\"\n",
        "        Universal fetcher with auto-fallback\n",
        "\n",
        "        Args:\n",
        "            symbol: Stock ticker symbol\n",
        "            prefer_source: 'alpha_vantage', 'polygon', 'finnhub', or 'yfinance'\n",
        "        \"\"\"\n",
        "        fetchers = {\n",
        "            'alpha_vantage': self.fetch_alpha_vantage,\n",
        "            'polygon': self.fetch_polygon,\n",
        "            'finnhub': self.fetch_finnhub,\n",
        "            'yfinance': self.fetch_yfinance\n",
        "        }\n",
        "\n",
        "        # Try preferred source first\n",
        "        if prefer_source and prefer_source in fetchers:\n",
        "            df = fetchers[prefer_source](symbol)\n",
        "            if df is not None and not df.empty:\n",
        "                return df\n",
        "\n",
        "        # Fallback to all sources\n",
        "        for name, fetcher in fetchers.items():\n",
        "            if prefer_source == name:  # Skip if already tried\n",
        "                continue\n",
        "            df = fetcher(symbol)\n",
        "            if df is not None and not df.empty:\n",
        "                print(f\"\\nâœ… Data fetched successfully from: {self.last_source}\")\n",
        "                return df\n",
        "\n",
        "        print(\"âŒ All APIs failed â€” please check keys and connection.\")\n",
        "        return None\n"
      ],
      "metadata": {
        "id": "F_5S5yPf8wgl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "class AdvancedFeatureEngineer:\n",
        "    \"\"\"Full-featured technical indicator generator for trading analysis\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.feature_names = []\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ“Œ MASTER FEATURE FUNCTION\n",
        "    # =============================================================\n",
        "    def add_all_features(self, df):\n",
        "        df = df.copy()\n",
        "\n",
        "        # Basic reference series\n",
        "        close, high, low, volume = df['close'], df['high'], df['low'], df['volume']\n",
        "\n",
        "        # Core Indicators\n",
        "        df = self._add_sma_ema(df)\n",
        "        df = self._add_macd(df)\n",
        "        df = self._add_rsi(df)\n",
        "        df = self._add_stochastic(df)\n",
        "        df = self._add_adx(df)\n",
        "        df = self._add_demarker(df)\n",
        "        df = self._add_atr(df)\n",
        "        df = self._add_bollinger(df)\n",
        "        df = self._add_std_features(df)\n",
        "        df = self._add_obv(df)\n",
        "        df = self._add_accumulation_distribution(df)\n",
        "        df = self._add_pivot_points(df)\n",
        "        df = self._add_trendlines(df)\n",
        "        df = self._add_market_profile(df)\n",
        "        df = self._add_support_resistance(df)\n",
        "\n",
        "        df.dropna(inplace=True)\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ“Š SIMPLE MOVING AVERAGES (SMA / EMA)\n",
        "    # =============================================================\n",
        "    def _add_sma_ema(self, df):\n",
        "        for period in [5, 10, 20, 50, 100, 200]:\n",
        "            df[f'sma_{period}'] = df['close'].rolling(period).mean()\n",
        "            df[f'ema_{period}'] = df['close'].ewm(span=period, adjust=False).mean()\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ’¹ MACD\n",
        "    # =============================================================\n",
        "    def _add_macd(self, df):\n",
        "        exp1 = df['close'].ewm(span=12, adjust=False).mean()\n",
        "        exp2 = df['close'].ewm(span=26, adjust=False).mean()\n",
        "        df['macd'] = exp1 - exp2\n",
        "        df['macd_signal'] = df['macd'].ewm(span=9, adjust=False).mean()\n",
        "        df['macd_hist'] = df['macd'] - df['macd_signal']\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ’ª RSI\n",
        "    # =============================================================\n",
        "    def _add_rsi(self, df, period=14):\n",
        "        delta = df['close'].diff()\n",
        "        gain = (delta.where(delta > 0, 0)).rolling(period).mean()\n",
        "        loss = (-delta.where(delta < 0, 0)).rolling(period).mean()\n",
        "        rs = gain / (loss + 1e-10)\n",
        "        df[f'rsi_{period}'] = 100 - (100 / (1 + rs))\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ¯ STOCHASTIC OSCILLATOR\n",
        "    # =============================================================\n",
        "    def _add_stochastic(self, df, period=14):\n",
        "        low_min = df['low'].rolling(period).min()\n",
        "        high_max = df['high'].rolling(period).max()\n",
        "        df[f'stoch_k_{period}'] = 100 * (df['close'] - low_min) / (high_max - low_min + 1e-10)\n",
        "        df[f'stoch_d_{period}'] = df[f'stoch_k_{period}'].rolling(3).mean()\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ“ ADX (Average Directional Index)\n",
        "    # =============================================================\n",
        "    def _add_adx(self, df, period=14):\n",
        "        high, low, close = df['high'], df['low'], df['close']\n",
        "        plus_dm = high.diff()\n",
        "        minus_dm = -low.diff()\n",
        "        plus_dm[plus_dm < 0] = 0\n",
        "        minus_dm[minus_dm < 0] = 0\n",
        "        tr = self._calculate_atr(df, period)\n",
        "        plus_di = 100 * (plus_dm.rolling(period).mean() / tr)\n",
        "        minus_di = 100 * (minus_dm.rolling(period).mean() / tr)\n",
        "        dx = 100 * abs(plus_di - minus_di) / (plus_di + minus_di + 1e-10)\n",
        "        df['adx'] = dx.rolling(period).mean()\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ§­ DEMARKER INDICATOR\n",
        "    # =============================================================\n",
        "    def _add_demarker(self, df, period=14):\n",
        "        demax = df['high'].diff()\n",
        "        demin = df['low'].diff()\n",
        "        demax = np.where(demax > 0, demax, 0)\n",
        "        demin = np.where(demin < 0, abs(demin), 0)\n",
        "        demax_sma = pd.Series(demax).rolling(period).mean()\n",
        "        demin_sma = pd.Series(demin).rolling(period).mean()\n",
        "        df['demarker'] = demax_sma / (demax_sma + demin_sma + 1e-10)\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ“‰ ATR (Average True Range)\n",
        "    # =============================================================\n",
        "    def _add_atr(self, df, period=14):\n",
        "        df['atr'] = self._calculate_atr(df, period)\n",
        "        return df\n",
        "\n",
        "    def _calculate_atr(self, df, period=14):\n",
        "        tr1 = df['high'] - df['low']\n",
        "        tr2 = abs(df['high'] - df['close'].shift())\n",
        "        tr3 = abs(df['low'] - df['close'].shift())\n",
        "        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)\n",
        "        return tr.rolling(period).mean()\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ¢ BOLLINGER BANDS\n",
        "    # =============================================================\n",
        "    def _add_bollinger(self, df, period=20):\n",
        "        sma = df['close'].rolling(period).mean()\n",
        "        std = df['close'].rolling(period).std()\n",
        "        df['bb_upper'] = sma + (2 * std)\n",
        "        df['bb_lower'] = sma - (2 * std)\n",
        "        df['bb_width'] = (df['bb_upper'] - df['bb_lower']) / sma\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ§® STANDARD DEVIATION FEATURES\n",
        "    # =============================================================\n",
        "    def _add_std_features(self, df):\n",
        "        for period in [10, 20, 50]:\n",
        "            df[f'std_{period}'] = df['close'].rolling(period).std()\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ’° ON-BALANCE VOLUME (OBV)\n",
        "    # =============================================================\n",
        "    def _add_obv(self, df):\n",
        "        obv = [0]\n",
        "        for i in range(1, len(df)):\n",
        "            if df['close'][i] > df['close'][i-1]:\n",
        "                obv.append(obv[-1] + df['volume'][i])\n",
        "            elif df['close'][i] < df['close'][i-1]:\n",
        "                obv.append(obv[-1] - df['volume'][i])\n",
        "            else:\n",
        "                obv.append(obv[-1])\n",
        "        df['obv'] = obv\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ§© ACCUMULATION/DISTRIBUTION LINE\n",
        "    # =============================================================\n",
        "    def _add_accumulation_distribution(self, df):\n",
        "        mfm = ((df['close'] - df['low']) - (df['high'] - df['close'])) / (df['high'] - df['low'] + 1e-10)\n",
        "        df['ad_line'] = (mfm * df['volume']).cumsum()\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸªœ PIVOT POINTS\n",
        "    # =============================================================\n",
        "    def _add_pivot_points(self, df):\n",
        "        df['pivot'] = (df['high'] + df['low'] + df['close']) / 3\n",
        "        df['r1'] = 2 * df['pivot'] - df['low']\n",
        "        df['s1'] = 2 * df['pivot'] - df['high']\n",
        "        df['r2'] = df['pivot'] + (df['high'] - df['low'])\n",
        "        df['s2'] = df['pivot'] - (df['high'] - df['low'])\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ“ˆ TRENDLINES (linear regression slope proxy)\n",
        "    # =============================================================\n",
        "    def _add_trendlines(self, df, period=20):\n",
        "        df['trend_slope'] = df['close'].rolling(period).apply(\n",
        "            lambda x: np.polyfit(range(len(x)), x, 1)[0], raw=True)\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ—ï¸ MARKET PROFILE (volume distribution)\n",
        "    # =============================================================\n",
        "    def _add_market_profile(self, df, bins=20):\n",
        "        df['price_bin'] = pd.qcut(df['close'], bins, duplicates='drop')\n",
        "        volume_profile = df.groupby('price_bin')['volume'].sum()\n",
        "        df['market_profile_strength'] = df['price_bin'].map(volume_profile)\n",
        "        return df\n",
        "\n",
        "    # =============================================================\n",
        "    # ğŸ§­ SUPPORT/RESISTANCE LEVELS (local highs/lows)\n",
        "    # =============================================================\n",
        "    def _add_support_resistance(self, df, window=10):\n",
        "        df['support'] = df['low'].rolling(window).min()\n",
        "        df['resistance'] = df['high'].rolling(window).max()\n",
        "        df['price_position'] = (df['close'] - df['support']) / (df['resistance'] - df['support'] + 1e-10)\n",
        "        return df\n"
      ],
      "metadata": {
        "id": "uZXcysxX8v_7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==================== CUSTOM ATTENTION LAYER ====================\n",
        "class CustomAttention(tf.keras.layers.Layer):\n",
        "    \"\"\"Custom attention mechanism for better interpretability\"\"\"\n",
        "\n",
        "    def __init__(self, units=128, **kwargs):\n",
        "        super(CustomAttention, self).__init__(**kwargs)\n",
        "        self.units = units\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(\n",
        "            shape=(input_shape[-1], self.units),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True,\n",
        "            name='attention_W'\n",
        "        )\n",
        "        self.b = self.add_weight(\n",
        "            shape=(self.units,),\n",
        "            initializer='zeros',\n",
        "            trainable=True,\n",
        "            name='attention_b'\n",
        "        )\n",
        "        self.u = self.add_weight(\n",
        "            shape=(self.units,),\n",
        "            initializer='glorot_uniform',\n",
        "            trainable=True,\n",
        "            name='attention_u'\n",
        "        )\n",
        "        super(CustomAttention, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        # x shape: (batch_size, time_steps, features)\n",
        "        uit = tf.nn.tanh(tf.tensordot(x, self.W, axes=1) + self.b)\n",
        "        ait = tf.tensordot(uit, self.u, axes=1)\n",
        "        attention_weights = tf.nn.softmax(ait, axis=1)\n",
        "        attention_weights = tf.expand_dims(attention_weights, axis=-1)\n",
        "        weighted_input = x * attention_weights\n",
        "        output = tf.reduce_sum(weighted_input, axis=1)\n",
        "        return output, attention_weights\n",
        "\n",
        "\n",
        "# ==================== ENHANCED MODEL ARCHITECTURE ====================\n",
        "class EnhancedLSTMModel:\n",
        "    \"\"\"\n",
        "    Advanced LSTM with multiple improvements:\n",
        "    - Custom attention mechanism\n",
        "    - Residual connections\n",
        "    - Optional CNN feature extraction\n",
        "    - Advanced regularization\n",
        "    - Learning rate scheduling\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, sequence_length, n_features,\n",
        "                 lstm_units=[128, 64],\n",
        "                 use_gru=False,\n",
        "                 use_cnn=False,\n",
        "                 dropout_rate=0.3,\n",
        "                 l2_reg=0.001,\n",
        "                 attention_units=64):\n",
        "        self.sequence_length = sequence_length\n",
        "        self.n_features = n_features\n",
        "        self.lstm_units = lstm_units\n",
        "        self.use_gru = use_gru\n",
        "        self.use_cnn = use_cnn\n",
        "        self.dropout_rate = dropout_rate\n",
        "        self.l2_reg = l2_reg\n",
        "        self.attention_units = attention_units\n",
        "        self.model = None\n",
        "        self.history = None\n",
        "\n",
        "    def build(self):\n",
        "        \"\"\"Build enhanced model with all improvements\"\"\"\n",
        "        inputs = Input(shape=(self.sequence_length, self.n_features))\n",
        "\n",
        "        # Optional: CNN for temporal feature extraction\n",
        "        if self.use_cnn:\n",
        "            x = Conv1D(filters=64, kernel_size=3, activation='relu', padding='same')(inputs)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Dropout(self.dropout_rate * 0.5)(x)\n",
        "        else:\n",
        "            x = inputs\n",
        "\n",
        "        # Choose between LSTM and GRU\n",
        "        RNNLayer = GRU if self.use_gru else LSTM\n",
        "\n",
        "        # First RNN layer (Bidirectional)\n",
        "        x = Bidirectional(\n",
        "            RNNLayer(\n",
        "                self.lstm_units[0],\n",
        "                return_sequences=True,\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(self.l2_reg),\n",
        "                recurrent_dropout=0.1\n",
        "            )\n",
        "        )(x)\n",
        "        x = LayerNormalization()(x)\n",
        "        x = Dropout(self.dropout_rate)(x)\n",
        "\n",
        "        # Second RNN layer\n",
        "        lstm_out = Bidirectional(\n",
        "            RNNLayer(\n",
        "                self.lstm_units[1],\n",
        "                return_sequences=True,\n",
        "                kernel_regularizer=tf.keras.regularizers.l2(self.l2_reg),\n",
        "                recurrent_dropout=0.1\n",
        "            )\n",
        "        )(x)\n",
        "        lstm_out = LayerNormalization()(lstm_out)\n",
        "\n",
        "        # Custom Attention mechanism\n",
        "        attention_output, attention_weights = CustomAttention(\n",
        "            units=self.attention_units\n",
        "        )(lstm_out)\n",
        "        attention_output = Dropout(self.dropout_rate)(attention_output)\n",
        "\n",
        "        # Residual connection from input\n",
        "        residual = Dense(self.lstm_units[1] * 2, activation='linear')(inputs)\n",
        "        residual = GlobalAveragePooling1D()(residual)\n",
        "\n",
        "        # Combine attention output with residual\n",
        "        x = Add()([attention_output, residual])\n",
        "        x = LayerNormalization()(x)\n",
        "\n",
        "        # Dense layers with progressive dropout\n",
        "        x = Dense(64, activation='relu',\n",
        "                 kernel_regularizer=tf.keras.regularizers.l2(self.l2_reg))(x)\n",
        "        x = BatchNormalization()(x)\n",
        "        x = Dropout(self.dropout_rate)(x)\n",
        "\n",
        "        x = Dense(32, activation='relu')(x)\n",
        "        x = Dropout(self.dropout_rate * 0.5)(x)\n",
        "\n",
        "        # Output layer\n",
        "        outputs = Dense(1, activation='linear')(x)\n",
        "\n",
        "        self.model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "        # Learning rate schedule with warmup\n",
        "        lr_schedule = tf.keras.optimizers.schedules.CosineDecayRestarts(\n",
        "            initial_learning_rate=0.001,\n",
        "            first_decay_steps=1000,\n",
        "            t_mul=2.0,\n",
        "            m_mul=0.9,\n",
        "            alpha=0.0001\n",
        "        )\n",
        "\n",
        "        optimizer = Adam(learning_rate=lr_schedule, clipnorm=1.0)\n",
        "\n",
        "        self.model.compile(\n",
        "            optimizer=optimizer,\n",
        "            loss='huber',\n",
        "            metrics=['mae', 'mse', tf.keras.metrics.RootMeanSquaredError(name='rmse')]\n",
        "        )\n",
        "\n",
        "        return self.model\n",
        "\n",
        "    def get_callbacks(self, checkpoint_path='best_model.keras', patience=15):\n",
        "        \"\"\"Get training callbacks\"\"\"\n",
        "        callbacks = [\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=patience,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=5,\n",
        "                min_lr=1e-7,\n",
        "                verbose=1\n",
        "            ),\n",
        "            ModelCheckpoint(\n",
        "                checkpoint_path,\n",
        "                monitor='val_loss',\n",
        "                save_best_only=True,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "        return callbacks\n",
        "\n",
        "    def train(self, X_train, y_train, X_val, y_val,\n",
        "              epochs=100, batch_size=32, checkpoint_path='best_model.keras'):\n",
        "        \"\"\"Train the model with callbacks\"\"\"\n",
        "        if self.model is None:\n",
        "            self.build()\n",
        "\n",
        "        callbacks = self.get_callbacks(checkpoint_path)\n",
        "\n",
        "        self.history = self.model.fit(\n",
        "            X_train, y_train,\n",
        "            validation_data=(X_val, y_val),\n",
        "            epochs=epochs,\n",
        "            batch_size=batch_size,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        return self.history\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Make predictions\"\"\"\n",
        "        return self.model.predict(X)\n",
        "\n",
        "    def summary(self):\n",
        "        \"\"\"Print model summary\"\"\"\n",
        "        if self.model is None:\n",
        "            self.build()\n",
        "        return self.model.summary()\n",
        "\n",
        "\n",
        "# ==================== ENSEMBLE MODEL ====================\n",
        "class EnsembleModel:\n",
        "    \"\"\"Ensemble of multiple models for better predictions\"\"\"\n",
        "\n",
        "    def __init__(self, n_models=3, **model_kwargs):\n",
        "        self.n_models = n_models\n",
        "        self.model_kwargs = model_kwargs\n",
        "        self.models = []\n",
        "\n",
        "    def build_and_train(self, X_train, y_train, X_val, y_val, **train_kwargs):\n",
        "        \"\"\"Build and train ensemble of models\"\"\"\n",
        "        for i in range(self.n_models):\n",
        "            print(f\"\\n{'='*50}\")\n",
        "            print(f\"Training Model {i+1}/{self.n_models}\")\n",
        "            print(f\"{'='*50}\\n\")\n",
        "\n",
        "            model = EnhancedLSTMModel(**self.model_kwargs)\n",
        "            model.build()\n",
        "\n",
        "            checkpoint_path = f'ensemble_model_{i+1}.keras'\n",
        "            model.train(X_train, y_train, X_val, y_val,\n",
        "                       checkpoint_path=checkpoint_path, **train_kwargs)\n",
        "\n",
        "            self.models.append(model)\n",
        "\n",
        "    def predict(self, X):\n",
        "        \"\"\"Average predictions from all models\"\"\"\n",
        "        predictions = np.array([model.predict(X) for model in self.models])\n",
        "        return np.mean(predictions, axis=0)\n",
        "\n",
        "\n",
        "# ==================== USAGE EXAMPLE ====================\n",
        "if __name__ == \"__main__\":\n",
        "    # Example usage\n",
        "    sequence_length = 60\n",
        "    n_features = 10\n",
        "\n",
        "    # Single model\n",
        "    model = EnhancedLSTMModel(\n",
        "        sequence_length=sequence_length,\n",
        "        n_features=n_features,\n",
        "        lstm_units=[128, 64],\n",
        "        use_gru=False,  # Set to True to use GRU instead\n",
        "        use_cnn=False,  # Set to True to add CNN layers\n",
        "        dropout_rate=0.3,\n",
        "        l2_reg=0.001,\n",
        "        attention_units=64\n",
        "    )\n",
        "\n",
        "    model.build()\n",
        "    model.summary()\n",
        "\n",
        "    # Example training (with dummy data)\n",
        "    # X_train, y_train = your_training_data\n",
        "    # X_val, y_val = your_validation_data\n",
        "    # history = model.train(X_train, y_train, X_val, y_val, epochs=100, batch_size=32)\n",
        "\n",
        "    # Ensemble model (recommended for production)\n",
        "    # ensemble = EnsembleModel(\n",
        "    #     n_models=3,\n",
        "    #     sequence_length=sequence_length,\n",
        "    #     n_features=n_features,\n",
        "    #     lstm_units=[128, 64],\n",
        "    #     dropout_rate=0.3\n",
        "    # )\n",
        "    # ensemble.build_and_train(X_train, y_train, X_val, y_val, epochs=100, batch_size=32)\n",
        "    # predictions = ensemble.predict(X_test)"
      ],
      "metadata": {
        "id": "QatZGYB8VCQp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "outputId": "18d5ec99-ad5d-4637-dd22-e62f4b1df095"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m10\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
              "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_2     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚    \u001b[38;5;34m142,336\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚        \u001b[38;5;34m512\u001b[0m â”‚ bidirectional_2[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m256\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_3     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚    \u001b[38;5;34m164,352\u001b[0m â”‚ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚        \u001b[38;5;34m256\u001b[0m â”‚ bidirectional_3[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
              "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ custom_attention_1  â”‚ [(\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m),     â”‚      \u001b[38;5;34m8,320\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”‚ (\u001b[38;5;33mCustomAttention\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m1\u001b[0m)]    â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m60\u001b[0m, \u001b[38;5;34m128\u001b[0m)   â”‚      \u001b[38;5;34m1,408\u001b[0m â”‚ input_layer_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ custom_attentionâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (\u001b[38;5;33mAdd\u001b[0m)         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m256\u001b[0m â”‚ add_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       â”‚\n",
              "â”‚ (\u001b[38;5;33mLayerNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ dropout_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dense_6[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         â”‚         \u001b[38;5;34m33\u001b[0m â”‚ dropout_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
              "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
              "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
              "â”‚ input_layer_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_2     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">142,336</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ bidirectional_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ bidirectional_3     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> â”‚ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ custom_attention_1  â”‚ [(<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>),     â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomAttention</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)]    â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">60</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)   â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,408</span> â”‚ input_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ custom_attentionâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ add_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  â”‚\n",
              "â”‚                     â”‚                   â”‚            â”‚ global_average_pâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ layer_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ add_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LayerNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ layer_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ dropout_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dense_6[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
              "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
              "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> â”‚ dropout_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
              "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m328,065\u001b[0m (1.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">328,065</span> (1.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m327,937\u001b[0m (1.25 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">327,937</span> (1.25 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m128\u001b[0m (512.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> (512.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bCoyTxXIBGjB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P6-SSOPIBdvn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}